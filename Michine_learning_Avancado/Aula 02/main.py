# KMN e SVN

# ============================================================
# AnÃ¡lise e Modelagem de Dados de Recrutamento
# ============================================================
# Passo a passo deste notebook/script:
#
# 1. Leitura e visualizaÃ§Ã£o inicial dos dados
# 2. AnÃ¡lise exploratÃ³ria: valores Ãºnicos, estatÃ­sticas, valores nulos
# 3. VisualizaÃ§Ã£o de dados: grÃ¡ficos de distribuiÃ§Ã£o, boxplots, swarmplots, violin plots, pairplots, heatmaps
# 4. PrÃ©-processamento: tratamento de nulos, Label Encoding, One Hot Encoding
# 5. Nova anÃ¡lise de correlaÃ§Ã£o apÃ³s encoding
# 6. SeleÃ§Ã£o de features e target
# 7. SeparaÃ§Ã£o em treino e teste
# 8. Escalonamento dos dados
# 9. Treinamento e avaliaÃ§Ã£o do modelo KNN (incluindo busca do melhor K)
# 10. Treinamento e avaliaÃ§Ã£o do modelo SVM
# 11. ObservaÃ§Ãµes e exemplos de pipelines para outros modelos
# ============================================================

import pandas as pd

# ğŸ“¥ Lendo a base de dados
print("\nğŸ“¥ Lendo a base de dados...")
dados = pd.read_excel('Michine_learning_Avancado\Aula 02\Recrutamento.xlsx')
print("Formato dos dados:", dados.shape)
print("Primeiras linhas do DataFrame:")
print(dados.head(10))

# ğŸ” Checando valores Ãºnicos da coluna status
print("\nğŸ” Checando valores Ãºnicos da coluna 'status'...")
print("Valores Ãºnicos em status:", set(dados.status))

# ğŸ“Š EstatÃ­sticas descritivas
print("\nğŸ“Š EstatÃ­sticas descritivas das variÃ¡veis numÃ©ricas:")
print(dados.describe())

# ğŸ•³ï¸ Visualizando valores nulos
import missingno as msno 
print("\nğŸ•³ï¸ Visualizando valores nulos na base...")
msno.matrix(dados)
import matplotlib.pyplot as plt
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ§® Contando valores nulos por coluna
print("\nğŸ§® Contando valores nulos por coluna:")
print(dados.isnull().sum())

# ğŸ’° Visualizando distribuiÃ§Ã£o de salÃ¡rio por status
import seaborn as sb
print("\nğŸ’° Visualizando distribuiÃ§Ã£o de salÃ¡rio por status (boxplot)...")
sb.boxplot(x='status', y='salary', data=dados, palette='hls')
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ©¹ Preenchendo valores nulos de salÃ¡rio com 0
print("\nğŸ©¹ Preenchendo valores nulos de salÃ¡rio com 0...")
dados['salary'].fillna(value=0, inplace=True)
print("Valores nulos apÃ³s preenchimento:")
print(dados.isnull().sum())

# ğŸ“¦ AnÃ¡lise de outliers e distribuiÃ§Ã£o das variÃ¡veis numÃ©ricas
print("\nğŸ“¦ AnÃ¡lise de outliers e distribuiÃ§Ã£o das variÃ¡veis numÃ©ricas:")
for col in ["hsc_p", "degree_p", "etest_p", "mba_p", "salary"]:
    print(f"  ğŸ“¦ Boxplot e histograma para: {col}")
    sb.boxplot(x=dados[col])
    plt.show()  # <-- Adicionado para exibir o grÃ¡fico
    sb.histplot(data=dados, x=col)
    plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ“ Swarmplot: RelaÃ§Ã£o entre mba_p, status e experiÃªncia de trabalho
print("\nğŸ“ Swarmplot: RelaÃ§Ã£o entre mba_p, status e experiÃªncia de trabalho...")
sb.set_theme(style="whitegrid", palette="muted")
ax = sb.swarmplot(data=dados, x="mba_p", y="status", hue="workex")
ax.set(ylabel="")
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ‘©â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ Violin plot: SalÃ¡rio por especializaÃ§Ã£o e gÃªnero
print("\nğŸ‘©â€ğŸ’¼ğŸ‘¨â€ğŸ’¼ Violin plot: SalÃ¡rio por especializaÃ§Ã£o e gÃªnero...")
import plotly_express as px
fig = px.violin(dados, y="salary", x="specialisation", color="gender", box=True, points="all")
fig.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ“ˆ Pairplot: Scores acadÃªmicos por status
print("\nğŸ“ˆ Pairplot: Scores acadÃªmicos por status...")
sb.pairplot(dados, vars=['ssc_p','hsc_p','degree_p','mba_p','etest_p'], hue="status")
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ§© Matriz de correlaÃ§Ã£o das variÃ¡veis numÃ©ricas
print("\nğŸ§© Matriz de correlaÃ§Ã£o das variÃ¡veis numÃ©ricas (apenas colunas numÃ©ricas)...")
dados_numericos = dados.select_dtypes(include=['number'])
print("Colunas numÃ©ricas consideradas para a correlaÃ§Ã£o:", list(dados_numericos.columns))
correlation_matrix = dados_numericos.corr().round(2)
fig, ax = plt.subplots(figsize=(8,8))    
sb.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ·ï¸ Aplicando LabelEncoder nas colunas categÃ³ricas
print("\nğŸ·ï¸ Aplicando LabelEncoder nas colunas categÃ³ricas ['gender', 'workex', 'specialisation', 'status']...")
from sklearn.preprocessing import LabelEncoder
colunas = ['gender', 'workex', 'specialisation', 'status']
label_encoder = LabelEncoder()
for col in colunas:
    print(f"  â¡ï¸ Transformando coluna '{col}' em valores numÃ©ricos...")
    dados[col] = label_encoder.fit_transform(dados[col])
print("Primeiras linhas apÃ³s LabelEncoder:")
print(dados.head())

# ğŸ·ï¸â¡ï¸ğŸ”¢ One Hot Encoding para variÃ¡veis categÃ³ricas com mais de duas categorias
print("\nğŸ·ï¸â¡ï¸ğŸ”¢ Aplicando One Hot Encoding em 'hsc_s' e 'degree_t' (criando variÃ¡veis dummies)...")
dummy_hsc_s = pd.get_dummies(dados['hsc_s'], prefix='dummy')
dummy_degree_t = pd.get_dummies(dados['degree_t'], prefix='dummy')
print("Colunas criadas para 'hsc_s':", list(dummy_hsc_s.columns))
print("Colunas criadas para 'degree_t':", list(dummy_degree_t.columns))

print("â¡ï¸ Concatenando variÃ¡veis dummies ao DataFrame principal...")
dados_coeded = pd.concat([dados, dummy_hsc_s, dummy_degree_t], axis=1)

print("â¡ï¸ Removendo colunas originais categÃ³ricas ['hsc_s', 'degree_t', 'salary'] do DataFrame codificado...")
dados_coeded.drop(['hsc_s', 'degree_t', 'salary'], axis=1, inplace=True)
print("Colunas restantes apÃ³s remoÃ§Ã£o:", list(dados_coeded.columns))
print("Primeiras linhas apÃ³s One Hot Encoding e remoÃ§Ã£o das colunas originais:")
print(dados_coeded.head())

# ğŸ§© Nova matriz de correlaÃ§Ã£o apÃ³s encoding
print("\nğŸ§© Nova matriz de correlaÃ§Ã£o apÃ³s encoding (apenas variÃ¡veis numÃ©ricas)...")
dados_coeded_numerico = dados_coeded.select_dtypes(include=['number'])
print("Colunas numÃ©ricas consideradas para a nova correlaÃ§Ã£o:", list(dados_coeded_numerico.columns))
correlation_matrix = dados_coeded_numerico.corr().round(2)
fig, ax = plt.subplots(figsize=(12,12))    
sb.heatmap(data=correlation_matrix, annot=True, linewidths=.5, ax=ax)
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ”¬ Relplot: RelaÃ§Ã£o entre status e ssc_p
print("\nğŸ”¬ Relplot: RelaÃ§Ã£o entre status e ssc_p (apÃ³s encoding)...")
sb.relplot(x="status", y="ssc_p", hue="status", size="ssc_p",
           sizes=(40, 400), alpha=.5, palette="muted",
           height=6, data=dados_coeded)
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ SeleÃ§Ã£o de features e target
print("\nğŸ Selecionando features ['ssc_p', 'hsc_p', 'degree_p', 'workex', 'mba_p'] e target ['status'] para o modelo...")
x = dados_coeded[['ssc_p', 'hsc_p', 'degree_p', 'workex', 'mba_p']]
y = dados_coeded['status']
print("Features selecionadas:", list(x.columns))
print("Target selecionado: status")

# âœ‚ï¸ SeparaÃ§Ã£o em treino e teste
print("\nâœ‚ï¸ Separando dados em treino e teste (80% treino, 20% teste)...")
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=7)
print("Formato do treino:", x_train.shape)
print("Formato do teste:", x_test.shape)

# ğŸ“ Escalonamento dos dados
print("\nğŸ“ Escalonando os dados (StandardScaler)...")
from sklearn.preprocessing import StandardScaler, MinMaxScaler  
scaler = StandardScaler() 
scaler.fit(x_train)
x_train_escalonado = scaler.transform(x_train)
x_test_escalonado = scaler.transform(x_test) 
print("Exemplo de dados escalonados (primeira linha):", x_train_escalonado[0])

# ğŸ”¢ Testando diferentes valores de K para o KNN
print("\nğŸ”¢ Testando diferentes valores de K para o KNN (de 1 a 9)...")
import numpy as np
error = []
for i in range(1, 10):
    knn = KNeighborsClassifier(n_neighbors=i)
    knn.fit(x_train_escalonado, y_train)
    pred_i = knn.predict(x_test_escalonado)
    error.append(np.mean(pred_i != y_test))
print("Erros mÃ©dios para cada valor de K (de 1 a 9):", error)

plt.figure(figsize=(12, 6))
plt.plot(range(1, 10), error, color='red', linestyle='dashed', marker='o',
         markerfacecolor='blue', markersize=10)
plt.title('Error Rate K Value')
plt.xlabel('K Value')
plt.ylabel('Mean Error')
plt.show()  # <-- Adicionado para exibir o grÃ¡fico

# ğŸ¤– Treinando o modelo KNN com K=5
print("\nğŸ¤– Treinando o modelo KNN com K=5...")
modelo_classificador = KNeighborsClassifier(n_neighbors=5)
modelo_classificador.fit(x_train_escalonado, y_train) 

# ğŸ”® Fazendo previsÃµes com o modelo KNN
print("\nğŸ”® Fazendo previsÃµes com o modelo KNN...")
y_predito = modelo_classificador.predict(x_test_escalonado) 
print("PrevisÃµes do KNN:", y_predito)

# ğŸ† Avaliando a acurÃ¡cia do modelo KNN
from sklearn.metrics import accuracy_score
print("\nğŸ† Avaliando a acurÃ¡cia do modelo KNN...")
print("AcurÃ¡cia do KNN:", accuracy_score(y_test, y_predito))

# ğŸ¤– Testando com o modelo SVM
print("\nğŸ¤– Treinando e avaliando o modelo SVM (LinearSVC)...")
from sklearn.pipeline import Pipeline
from sklearn.svm import LinearSVC
svm = Pipeline([
    ("linear_svc", LinearSVC(C=1))
])
svm.fit(x_train_escalonado, y_train) 
y_predito_svm = svm.predict(x_test_escalonado) 
print("AcurÃ¡cia do SVM:", accuracy_score(y_test, y_predito_svm))

# ğŸ“Š Importando mÃ©tricas para possÃ­veis anÃ¡lises futuras
from sklearn import metrics
from sklearn.metrics import roc_curve, auc

# âš ï¸ AtenÃ§Ã£o: predict_proba nÃ£o estÃ¡ disponÃ­vel para LinearSVC, use outro classificador se necessÃ¡rio
# y_prob = modelo_classificador.predict_proba(x_test)[:,1] 

# ğŸ§ª Exemplo de pipeline para SVM polinomial (nÃ£o treinado aqui)
from sklearn.svm import SVC
poly_svm = Pipeline([
    ("svm", SVC(kernel="poly", degree=3, coef0=1, C=5))
])
# poly_svm.fit(x_train, y_train) # Descomente para treinar o SVM polinomial